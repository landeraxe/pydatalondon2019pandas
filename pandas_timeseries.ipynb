{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Open Power System (time series) data analysis\n",
    "\n",
    "https://open-power-system-data.org/ for daily consumption, wind, solar, solar+wind data.\n",
    "\n",
    "Credit: https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/\n",
    "\n",
    "Data: https://github.com/jenfly/opsd/raw/master/opsd_germany_daily.csv\n",
    "\n",
    "We will use:\n",
    "* pandas\n",
    "* matplotlib\n",
    "* seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date objects\n",
    "\n",
    "Datetime objects are timezone aware or unaware, generally you can't combine the two as it makes no sense to compare with and without a timezone. \n",
    "\n",
    "Generally speaking you're better off if you can convert a timeseries into one with a timezone (if you know it), then you preserve the timezone information. \n",
    "\n",
    "In this example we don't have timezones so we're working with timezone unaware dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2018-01-15 3:45pm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2018-01-15') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2018-01-15T15:45:00Z') # ISO 8601 is a sane way to consistently deal with dates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2018-01-15 3:45pm', utc=True) # note inclusion of UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('7/8/1952') # defaults to MM/DD/YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('7/8/1952', dayfirst=True) # you can override for DD/MM/YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can generate ranges easily\n",
    "pd.date_range(start=\"2018-01-01\", freq=\"1D\", periods=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequencies look like:\n",
    "* D daily, B business daily (e.g. 5D means 5 day gaps)\n",
    "* W weekly, M monthly, Q quarterly, A annually\n",
    "* H hourly, min by the minute\n",
    "\n",
    "See them here: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might use ranges to:\n",
    "\n",
    "* clean up imported data that lacks datetime information\n",
    "* create a mask to select ranges of data from a larger set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.timedelta_range(start='1 day', end='5 day', periods=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.timedelta_range(start='1 day', periods=24, freq='H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our data\n",
    "\n",
    "Convenience functiosn include `read_csv`, `read_table`, `read_hdf5`, `read_sql` and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily = pd.read_csv('opsd_germany_daily.csv')\n",
    "opsd_daily.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily = opsd_daily.set_index('Date')\n",
    "opsd_daily.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a shortcut method to load by setting the index to a known column\n",
    "opsd_daily = pd.read_csv('opsd_germany_daily.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns with year, month, and weekday name\n",
    "opsd_daily['Year'] = opsd_daily.index.year\n",
    "opsd_daily['Month'] = opsd_daily.index.month\n",
    "opsd_daily['Weekday Name'] = opsd_daily.index.day_name()\n",
    "opsd_daily['Weekday'] = opsd_daily.index.weekday\n",
    "# isin lets us test for set membership\n",
    "opsd_daily['Is Weekend'] = opsd_daily['Weekday'].isin((5, 6))\n",
    "opsd_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_copy = opsd_daily.reset_index()\n",
    "opsd_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opsd_copy['Date'].year # won't work\n",
    "opsd_copy['Date'].dt.year.sample(5) # will work - off of an index we have a regular column\n",
    "# we need to dip down one level to get the datetime tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a random sampling of 5 rows\n",
    "opsd_daily.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily['Weekday Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.loc['2017-08-10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note INCLUSIVE end indexing - different to usual indexing!\n",
    "# THIS IS NOVEL - BE AWARE!\n",
    "opsd_daily.loc['2014-01-20':'2014-01-22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.loc['2012-02'] # partial matches are supported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Display figures inline in Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # Seaborn is a statistical plotting library\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set(rc={'figure.figsize':(11, 4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily['Consumption'].plot(linewidth=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_plot = ['Consumption', 'Solar', 'Wind']\n",
    "axes = opsd_daily[cols_plot].plot(marker='.', alpha=0.5, linestyle='None', figsize=(11, 9), subplots=True)\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('Daily Totals (GWh)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see two general behaviours for Consumption (hypothesis - weekday and weekend?). \n",
    "\n",
    "Solar starts later than Wind with many years of missing (NaN) data.\n",
    "\n",
    "Consumption is higher in winter. Wind and Solar production appear to be increasing over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What patterns do you see below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = opsd_daily.loc['2017', 'Consumption'].plot()\n",
    "ax.set_ylabel('Daily Consumption (GWh)');\n",
    "ax.set_title(\"2017's Consumption by day\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - can you group the data to get monthly means for Consumption?\n",
    "\n",
    "You'll first want to get the 2017 subset of data for `['Consumption', 'Month']`. Does it look sensible?\n",
    "\n",
    "Next you can `groupby` on the Month column. Next you need to call one of the functions, we're after the mean but there's also sum, median, std, var, min etc. Try these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now take the above answer and add a .plot() to graph it\n",
    "# plot returns an axis object, if you take `ax = <your code>` then on a new line you can add a title like\n",
    "# ax.set_title('Mean monthly consumption for 2017');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drilling further - it looks like we do have daily behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = opsd_daily.loc['2017-01':'2017-02', 'Consumption'].plot(marker='o', linestyle='-')\n",
    "ax.set_ylabel('Daily Consumption (GWh)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(opsd_daily.loc['2017-01':'2017-02', 'Consumption'], marker='o', linestyle='-')\n",
    "ax.set_ylabel('Daily Consumption (GWh)')\n",
    "ax.set_title('Jan-Feb 2017 Electricity Consumption')\n",
    "# Set x-axis major ticks to weekly interval, on Mondays\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MONDAY))\n",
    "# Format x-tick labels as 3-letter month name and day number\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping on the weekday to see mean behaviour by day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_by_weekday = opsd_daily.loc['2017', ['Consumption', 'Weekday']].groupby('Weekday').mean()\n",
    "mean_by_weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_by_weekday.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_week = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n",
    "new_index = mean_by_weekday.index.map(day_of_week)\n",
    "mean_by_weekday.set_index(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_by_weekday.set_index(new_index).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarising seasonality with seaborn\n",
    "\n",
    "What patterns do we see below? General patterns? Outliers?\n",
    "\n",
    "This is for all data, not just 2017, so what might we conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(11, 10), sharex=True)\n",
    "for name, ax in zip(['Consumption', 'Solar', 'Wind'], axes):\n",
    "    sns.boxplot(data=opsd_daily, x='Month', y=name, ax=ax)\n",
    "    ax.set_ylabel('GWh')\n",
    "    ax.set_title(name)\n",
    "    # Remove the automatic x-axis label from all but the bottom subplot\n",
    "    if ax != axes[-1]:\n",
    "        ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=opsd_daily, x='Weekday Name', y='Consumption');\n",
    "# note ordering is built from the natural order in the underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_week.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the outliers telling us? \n",
    "sns.boxplot(data=opsd_daily, x='Weekday Name', y='Consumption', order=day_of_week.values());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are any of these German holidays? I'm curious!\n",
    "# New Year's Eve, Christmas Eve\n",
    "daily_mask = opsd_daily['Weekday Name'] == 'Monday'\n",
    "opsd_daily[daily_mask].query(\"Consumption < 1000\").sort_values('Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation and lags\n",
    "\n",
    "How similar is today's point to the same point N days in the future? Autocorrelation tests all frequencies.\n",
    "\n",
    "Lags look at 1 frequency (default is 1 unit ahead, for us that's 1 day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_plot(opsd_daily.Consumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots();\n",
    "autocorrelation_plot(opsd_daily.Consumption, ax=ax)\n",
    "ax.set_xlim(0, 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots();\n",
    "autocorrelation_plot(opsd_daily.Consumption, ax=ax)\n",
    "ax.set_xlim(0, 360);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lag plot shows structure between $y(t)$ and $y(t+1)$. A visual relationships suggest that there's structure in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import lag_plot\n",
    "\n",
    "data = opsd_daily.loc['2013']\n",
    "lag_plot(data['Consumption']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_plot(data['Consumption'], c=data['Is Weekend'][:-1], cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the days to day-names list\n",
    "opsd_daily[['Weekday', 'Weekday Name']].drop_duplicates().sort_values('Weekday')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - can you show the lag plot by day of week using Weekday?\n",
    "\n",
    "Viridis goes from purple (0) to green to yellow (1) - so do we see daily structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date ranges again and resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that freq is set\n",
    "pd.date_range('2004-09-20', periods=8, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opsd_daily.index[:5] # note that freq isn't as it came from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a small copy\n",
    "times_sample = pd.to_datetime(['2013-02-03', '2013-02-06', '2013-02-08'])\n",
    "# Select the specified dates and just the Consumption column\n",
    "consum_sample = opsd_daily.loc[times_sample, ['Consumption']].copy()\n",
    "consum_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to daily frequency, without filling any missings\n",
    "consum_freq = consum_sample.asfreq('D')\n",
    "consum_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column with missings forward filled\n",
    "consum_freq['Consumption - Forward Fill'] = consum_sample.asfreq('D', method='ffill')\n",
    "consum_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly resampling - downsampling our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the data columns we want to include (i.e. exclude Year, Month, Weekday Name)\n",
    "data_columns = ['Consumption', 'Wind', 'Solar', 'Wind+Solar']\n",
    "# Resample to weekly frequency, aggregating with mean\n",
    "opsd_weekly_mean = opsd_daily[data_columns].resample('W').mean()\n",
    "opsd_weekly_mean.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's going on in this code? What do we expect to see?\n",
    "\n",
    "# Start and end of the date range to extract\n",
    "start, end = '2017-01', '2017-06'\n",
    "# Plot daily and weekly resampled time series together\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(opsd_daily.loc[start:end, 'Solar'],\n",
    "marker='.', linestyle='-', linewidth=0.5, label='Daily')\n",
    "ax.plot(opsd_weekly_mean.loc[start:end, 'Solar'],\n",
    "marker='o', markersize=8, linestyle='-', label='Weekly Mean Resample')\n",
    "ax.set_ylabel('Solar Production (GWh)')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the centered 7-day rolling mean (not centrered, using history only)\n",
    "opsd_7d = opsd_daily[data_columns].rolling(7, center=False).mean()\n",
    "opsd_7d.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start and end of the date range to extract\n",
    "start, end = '2017-01', '2017-06'\n",
    "# Plot daily, weekly resampled, and 7-day rolling mean time series together\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(opsd_daily.loc[start:end, 'Solar'],\n",
    "marker='.', linestyle='-', linewidth=0.5, label='Daily')\n",
    "ax.plot(opsd_weekly_mean.loc[start:end, 'Solar'],\n",
    "marker='o', markersize=8, linestyle='-', label='Weekly Mean Resample')\n",
    "ax.plot(opsd_7d.loc[start:end, 'Solar'],\n",
    "marker='.', linestyle='-', label='7-d Rolling Mean')\n",
    "ax.set_ylabel('Solar Production (GWh)')\n",
    "ax.legend();\n",
    "\n",
    "# note that the 7d rolling is on a daily basis still\n",
    "# the weekly mean is at a week-at-a-time granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends\n",
    "\n",
    "If we plot a 365 trend vs a 7 day trend, what can we see for overall consumption and green energy production?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The min_periods=360 argument accounts for a few isolated missing days in the\n",
    "# wind and solar production time series\n",
    "opsd_365d = opsd_daily[data_columns].rolling(window=365, center=False, min_periods=360).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What can we observe in this plot?\n",
    "\n",
    "# Plot daily, 7-day rolling mean, and 365-day rolling mean time series\n",
    "fig, ax = plt.subplots(figsize=(14,4))\n",
    "ax.plot(opsd_daily['Consumption'], marker='.', markersize=2, color='0.6',\n",
    "linestyle='None', label='Daily')\n",
    "ax.plot(opsd_7d['Consumption'], linewidth=2, label='7-d Rolling Mean')\n",
    "ax.plot(opsd_365d['Consumption'], color='0.2', linewidth=3,\n",
    "label='Trend (365-d Rolling Mean)')\n",
    "# Set x-ticks to yearly interval and add legend and labels\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.legend()\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Consumption (GWh)')\n",
    "ax.set_title('Trends in Electricity Consumption');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do the same for solar and wind\n",
    "\n",
    "# Plot 365-day rolling mean time series of wind and solar power\n",
    "fig, ax = plt.subplots()\n",
    "for nm in ['Wind', 'Solar', 'Wind+Solar']:\n",
    "    ax.plot(opsd_365d[nm], label=nm)\n",
    "    # Set x-ticks to yearly interval, adjust y-axis limits, add legend and labels\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.set_ylim(0, 400)\n",
    "    ax.legend()\n",
    "    ax.set_ylabel('Production (GWh)')\n",
    "    ax.set_title('Trends in Electricity Production (365-d Rolling Means)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Share of green power over the years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the annual sums, setting the value to NaN for any year which has\n",
    "# fewer than 360 days of data\n",
    "opsd_annual = opsd_daily[data_columns].resample('A').sum(min_count=360)\n",
    "# The default index of the resampled DataFrame is the last day of each year,\n",
    "# ('2006-12-31', '2007-12-31', etc.) so to make life easier, set the index\n",
    "# to the year component\n",
    "opsd_annual = opsd_annual.set_index(opsd_annual.index.year)\n",
    "opsd_annual.index.name = 'Year'\n",
    "opsd_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - compute the fraction of  wind+solar to overall Consumption and plot it\n",
    "\n",
    "Add a y label, title and perhaps set the ylim to (0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We've covered datetimes, resampling, various plotting approaches to reveal structure in our data and you've grouped your data and created some additional visualisations.\n",
    "\n",
    "Now you might want to check:\n",
    "\n",
    "* Prophet (Facebook) for time series modeling\n",
    "* Timezones\n",
    "* `statsmodels` time series decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
